{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'minScale': 1.25, 'width': '80%'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup Reveal.JS\n",
    "from traitlets.config.manager import BaseJSONConfigManager\n",
    "from pathlib import Path\n",
    "path = Path.home() / \".jupyter\" / \"nbconfig\"\n",
    "cm = BaseJSONConfigManager(config_dir=str(path))\n",
    "# ipyleaflet hack to load full map in Reveal.js\n",
    "# These settings are also injected into the notebook metadata\n",
    "# (Edit -> Edit Notebook Metadata), which is the preferred method\n",
    "cm.update(\n",
    "    \"rise\",\n",
    "    {\"minScale\": 1.25,\n",
    "     \"width\": \"80%\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Computer says \"I Don't Know\"\n",
    "## The case for Honest AI\n",
    "\n",
    "Peter Flach, University of Bristol and Alan Turing Institute, UK\n",
    "\n",
    "[flach.github.io](https://flach.github.io)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Would you consider it newsworthy if a human passes a multiple-choice test? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Probably not. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Yet multiple-choice tests are behind many AI successes reported in the media, leading to recent headlines such as "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Researchers taught an AI to recognize smells!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- AI Trained on Old Scientific Papers Makes Discoveries Humans Missed!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- AI learns to recognize nerve cells!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We are then told that \"AI passed the test\" or \"the algorithm worked\" -- but what exactly does that mean? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Who sets the exam, and what is the passing grade?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "In this talk I will discuss why performance evaluation is not something that can be easily summarised in a catchy headline -- neither for humans nor for machines. \n",
    "\n",
    "Furthermore, I will argue why it is imperative that AI algorithms become more *honest* about their own abilities. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Quantifying the uncertainty in their predictions in the same way as weather forecasters do -- saying \"the chance of rain is 70%\" rather than \"it will rain\" -- would be a good start. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Quantifying the uncertainty in that chance estimate --  am I confident that 70% is close to the right number, or did I just guess that on the basis of the last three days? -- would be even better. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "But what would really demonstrate an AI algorithm's awareness of its own strengths *and* limitations is if it would occasionally say **\"I don't know\"** --\n",
    "- something that not many contemporary AI algorithms and machine-learned classifiers do\n",
    "- often leading to problems with \"adversarial examples\" which are doctored to mislead the algorithm. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "I will discuss in an accessible way how this arises due to a focus on *discriminative learning*, and how recent research has developed ways to overcome this, allowing AI and machine learning to become more **honest and aware of their own limitations**.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Second slide\n",
    "\n",
    "Example of ipyleaflet showing maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipyleaflet in /usr/local/lib/python3.9/site-packages (0.13.6)\n",
      "Requirement already satisfied: shapely in /usr/local/lib/python3.9/site-packages (from ipyleaflet) (1.7.1)\n",
      "Requirement already satisfied: ipywidgets<8,>=7.6.0 in /usr/local/lib/python3.9/site-packages (from ipyleaflet) (7.6.3)\n",
      "Requirement already satisfied: branca<0.5,>=0.3.1 in /usr/local/lib/python3.9/site-packages (from ipyleaflet) (0.4.2)\n",
      "Requirement already satisfied: traittypes<3,>=0.2.1 in /usr/local/lib/python3.9/site-packages (from ipyleaflet) (0.2.1)\n",
      "Requirement already satisfied: jupyterlab-widgets>=1.0.0; python_version >= \"3.6\" in /usr/local/lib/python3.9/site-packages (from ipywidgets<8,>=7.6.0->ipyleaflet) (1.0.0)\n",
      "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.9/site-packages (from ipywidgets<8,>=7.6.0->ipyleaflet) (3.5.1)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.9/site-packages (from ipywidgets<8,>=7.6.0->ipyleaflet) (5.1.2)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.9/site-packages (from ipywidgets<8,>=7.6.0->ipyleaflet) (5.0.5)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.9/site-packages (from ipywidgets<8,>=7.6.0->ipyleaflet) (5.5.0)\n",
      "Requirement already satisfied: ipython>=4.0.0; python_version >= \"3.3\" in /usr/local/lib/python3.9/site-packages (from ipywidgets<8,>=7.6.0->ipyleaflet) (7.20.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/site-packages (from branca<0.5,>=0.3.1->ipyleaflet) (2.11.3)\n",
      "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.9/site-packages (from widgetsnbextension~=3.5.0->ipywidgets<8,>=7.6.0->ipyleaflet) (6.2.0)\n",
      "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.9/site-packages (from nbformat>=4.2.0->ipywidgets<8,>=7.6.0->ipyleaflet) (4.7.1)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.9/site-packages (from nbformat>=4.2.0->ipywidgets<8,>=7.6.0->ipyleaflet) (3.2.0)\n",
      "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.9/site-packages (from nbformat>=4.2.0->ipywidgets<8,>=7.6.0->ipyleaflet) (0.2.0)\n",
      "Requirement already satisfied: appnope; platform_system == \"Darwin\" in /usr/local/lib/python3.9/site-packages (from ipykernel>=4.5.1->ipywidgets<8,>=7.6.0->ipyleaflet) (0.1.2)\n",
      "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.9/site-packages (from ipykernel>=4.5.1->ipywidgets<8,>=7.6.0->ipyleaflet) (6.1)\n",
      "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.9/site-packages (from ipykernel>=4.5.1->ipywidgets<8,>=7.6.0->ipyleaflet) (6.1.11)\n",
      "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.9/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets<8,>=7.6.0->ipyleaflet) (50.3.2)\n",
      "Requirement already satisfied: pickleshare in /usr/local/lib/python3.9/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets<8,>=7.6.0->ipyleaflet) (0.7.5)\n",
      "Requirement already satisfied: backcall in /usr/local/lib/python3.9/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets<8,>=7.6.0->ipyleaflet) (0.2.0)\n",
      "Requirement already satisfied: pygments in /usr/local/lib/python3.9/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets<8,>=7.6.0->ipyleaflet) (2.8.0)\n",
      "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.9/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets<8,>=7.6.0->ipyleaflet) (0.18.0)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.9/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets<8,>=7.6.0->ipyleaflet) (3.0.16)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.9/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets<8,>=7.6.0->ipyleaflet) (4.4.2)\n",
      "Requirement already satisfied: pexpect>4.3; sys_platform != \"win32\" in /usr/local/lib/python3.9/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets<8,>=7.6.0->ipyleaflet) (4.8.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.9/site-packages (from jinja2->branca<0.5,>=0.3.1->ipyleaflet) (1.1.1)\n",
      "Requirement already satisfied: nbconvert in /usr/local/lib/python3.9/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8,>=7.6.0->ipyleaflet) (6.0.7)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.9/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8,>=7.6.0->ipyleaflet) (0.9.2)\n",
      "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.9/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8,>=7.6.0->ipyleaflet) (0.9.0)\n",
      "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.9/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8,>=7.6.0->ipyleaflet) (20.1.0)\n",
      "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.9/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8,>=7.6.0->ipyleaflet) (22.0.3)\n",
      "Requirement already satisfied: Send2Trash>=1.5.0 in /usr/local/lib/python3.9/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8,>=7.6.0->ipyleaflet) (1.5.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /usr/local/lib/python3.9/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets<8,>=7.6.0->ipyleaflet) (0.17.3)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.9/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets<8,>=7.6.0->ipyleaflet) (20.3.0)\n",
      "Requirement already satisfied: six>=1.11.0 in /usr/local/lib/python3.9/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets<8,>=7.6.0->ipyleaflet) (1.15.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.9/site-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets<8,>=7.6.0->ipyleaflet) (2.8.1)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.9/site-packages (from jedi>=0.16->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets<8,>=7.6.0->ipyleaflet) (0.8.1)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.9/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets<8,>=7.6.0->ipyleaflet) (0.2.5)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.9/site-packages (from pexpect>4.3; sys_platform != \"win32\"->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets<8,>=7.6.0->ipyleaflet) (0.7.0)\n",
      "Requirement already satisfied: bleach in /usr/local/lib/python3.9/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8,>=7.6.0->ipyleaflet) (3.3.0)\n",
      "Requirement already satisfied: defusedxml in /usr/local/lib/python3.9/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8,>=7.6.0->ipyleaflet) (0.6.0)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.9/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8,>=7.6.0->ipyleaflet) (0.8.4)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.9/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8,>=7.6.0->ipyleaflet) (0.3)\n",
      "Requirement already satisfied: testpath in /usr/local/lib/python3.9/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8,>=7.6.0->ipyleaflet) (0.4.4)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.9/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8,>=7.6.0->ipyleaflet) (1.4.3)\n",
      "Requirement already satisfied: nbclient<0.6.0,>=0.5.0 in /usr/local/lib/python3.9/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8,>=7.6.0->ipyleaflet) (0.5.3)\n",
      "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.9/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8,>=7.6.0->ipyleaflet) (0.1.2)\n",
      "Requirement already satisfied: cffi>=1.0.0 in /usr/local/lib/python3.9/site-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8,>=7.6.0->ipyleaflet) (1.14.5)\n",
      "Requirement already satisfied: webencodings in /usr/local/lib/python3.9/site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8,>=7.6.0->ipyleaflet) (0.5.1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.9/site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8,>=7.6.0->ipyleaflet) (20.9)\n",
      "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.9/site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8,>=7.6.0->ipyleaflet) (1.5.1)\n",
      "Requirement already satisfied: async-generator in /usr/local/lib/python3.9/site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8,>=7.6.0->ipyleaflet) (1.10)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.9/site-packages (from cffi>=1.0.0->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8,>=7.6.0->ipyleaflet) (2.20)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.9/site-packages (from packaging->bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8,>=7.6.0->ipyleaflet) (2.4.7)\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ipyleaflet'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-7cf386fd82fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip3 install ipyleaflet'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mipyleaflet\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMarker\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'ipyleaflet'"
     ]
    }
   ],
   "source": [
    "!pip3 install ipyleaflet\n",
    "from ipyleaflet import Map, Marker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "center = (52.204793, 360.121558)\n",
    "m = Map(center=center, zoom=15)\n",
    "marker = Marker(location=center, draggable=True)\n",
    "m.add_layer(marker);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "display(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Example of heatmap on top of map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from ipyleaflet import Map, Heatmap\n",
    "from random import uniform\n",
    "m = Map(center=(0, 0), zoom=2)\n",
    "\n",
    "heatmap = Heatmap(\n",
    "    locations=[[uniform(-80, 80), uniform(-180, 180), uniform(0, 1000)] for i in range(2000)],\n",
    "    radius=20,\n",
    "    gradient={0.4: 'blue', 0.6: 'cyan', 0.7: 'lime', 0.8: 'yellow', 1.0: 'red'}\n",
    ")\n",
    "\n",
    "m.add_layer(heatmap);\n",
    "display(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Opendata Bristol\n",
    "\n",
    "Example of OpenData Bristol on top of Bristol's map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "air_quality_bristol_query = 'https://opendata.bristol.gov.uk/api/records/1.0/search/?dataset=air-quality-data-continuous&q=&rows=1000&sort=date_time&facet=date_time&facet=coordinates&facet=temp'\n",
    "\n",
    "import urllib, json\n",
    "\n",
    "response = urllib.request.urlopen(air_quality_bristol_query)\n",
    "\n",
    "data = json.loads(response.read())\n",
    "\n",
    "print('Json root keys')\n",
    "print(data.keys())\n",
    "print('3 records')\n",
    "data['records'][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def get_records(data, fields=None):\n",
    "    '''\n",
    "    data: json object\n",
    "    fields: list of strings\n",
    "        Each dictionary entry with the field name is retrieved in the given order\n",
    "    return\n",
    "    list of list of values\n",
    "    '''\n",
    "    for record in data['records']:\n",
    "        record_fields = record['fields']\n",
    "        if fields is None:\n",
    "            yield record_fields\n",
    "        else:\n",
    "            for key in fields:\n",
    "                yield [record_fields.get(key, np.nan) for key in fields]\n",
    "\n",
    "fields = ['date_time', 'geo_point_2d', 'temp', 'no', 'no2', 'nox']\n",
    "                \n",
    "record_values = list(get_records(data, fields=fields))\n",
    "\n",
    "record_values[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "m = Map(center=(51.454500, -2.587900), zoom=12)\n",
    "gradient={0.4: 'blue', 0.6: 'cyan', 0.7: 'lime', 0.8: 'yellow', 1.0: 'red'}\n",
    "\n",
    "position_id = []\n",
    "\n",
    "field_map = {field: i for i, field in enumerate(fields)}\n",
    "heatmap = Heatmap(\n",
    "    locations=[[values[field_map['geo_point_2d']][0],\n",
    "                values[field_map['geo_point_2d']][1],\n",
    "                values[field_map['no']]] for values in record_values],\n",
    "    radius=20,\n",
    "    gradient=gradient\n",
    ")\n",
    "\n",
    "m.add_layer(heatmap);\n",
    "display(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Pandas dataframe\n",
    "\n",
    "We will use pandas to analyse the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_records = pd.DataFrame(record_values, columns=fields)\n",
    "df_records[['Longitude', 'Latitude']] = pd.DataFrame(df_records['geo_point_2d'].tolist(), index= df_records.index)\n",
    "df_records = df_records.sort_values(by='date_time')\n",
    "df_records = df_records.drop_duplicates(subset=['Longitude', 'Latitude'], keep='first')\n",
    "df_records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Binary probabilistic classifier\n",
    "\n",
    "Simulation of a probabilistic classifier with a linear transformation to convert raw values into the interval [0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "df_records = df_records.dropna(subset=['no'])\n",
    "df_records['no_scaled'] = (df_records['no'] - df_records['no'].min())/(df_records['no'].max() - df_records['no'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "locations = df_records[['Longitude', 'Latitude', 'no_scaled']].values\n",
    "locations = [list(row) for row in locations]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "m = Map(center=(51.454500, -2.587900), zoom=12)\n",
    "gradient={0.0: 'blue', 1.0: 'red'}\n",
    "\n",
    "heatmap = Heatmap(\n",
    "    locations=locations,\n",
    "    radius=40,\n",
    "    gradient=gradient,\n",
    "    min_opacity=0.5,\n",
    ")\n",
    "\n",
    "m.add_layer(heatmap);\n",
    "display(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Simulate probabilistic linear classifier\n",
    "\n",
    "We start by a uniform value through all the map.\n",
    "\n",
    "The points are uniformly distributed across the latitude and longitude at 2 degrees on every direction. Because the equirectangular projection the latitude degrees seem to be more spaced on the poles, and very concentrated near the equator. The longitudinal distribution is not affected on this representation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from ipyleaflet import Map, Heatmap\n",
    "from random import uniform\n",
    "m = Map(center=(0, 0), zoom=0)\n",
    "\n",
    "\n",
    "nlon, nlat = (180, 90)\n",
    "lon = np.linspace(-180, 180, nlon)\n",
    "lat = np.linspace(-90, 90, nlat)\n",
    "lonv, latv = np.meshgrid(lon, lat, indexing='ij')\n",
    "probs = np.ones_like(lonv)*500 #100*(latv - latv.min())/(latv.max() - latv.min())\n",
    "\n",
    "heatmap = Heatmap(\n",
    "    locations=[[latv[i,j], lonv[i,j], probs[i,j]] for i in range(nlon) for j in range(nlat)],\n",
    "    radius=10,\n",
    "    gradient={0.0: 'blue', 1.0: 'red'}\n",
    ")\n",
    "\n",
    "m.add_layer(heatmap);\n",
    "display(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# North vs South\n",
    "\n",
    "Simulation of a probabilistic classifier that predicts the probability of North vs South poles.\n",
    "\n",
    "We will first generate a grid of 2 degrees in every direction and assign probabilities and will visualise in a Matplotlib heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "nlon, nlat = (180, 90)\n",
    "lon = np.linspace(-180, 180, nlon)\n",
    "lat = np.linspace(-90, 90, nlat)\n",
    "lonv, latv = np.meshgrid(lon, lat, indexing='ij')\n",
    "probs = 100*(latv - latv.min())/(latv.max() - latv.min())\n",
    "\n",
    "fig = plt.figure(figsize=(15, 5))\n",
    "for i, (name, matrix) in enumerate({'longitude': lonv, 'latitude': latv, 'probabilities': probs}.items()):\n",
    "    ax = fig.add_subplot(1, 3, i+1)\n",
    "    ax.set_title(name)\n",
    "    img = ax.imshow(matrix.T)\n",
    "    divider = make_axes_locatable(ax)\n",
    "    cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "    fig.colorbar(img, cax=cax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "If we show the probability of North it seems that the probability of South has an alpha transparency of 1.0. Making it difficult to see the South (yellow) predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from ipyleaflet import Map, Heatmap\n",
    "from random import uniform\n",
    "m = Map(center=(0, 0), zoom=0)\n",
    "\n",
    "nlon, nlat = (180, 90)\n",
    "lon = np.linspace(-180, 180, nlon)\n",
    "lat = np.linspace(-90, 90, nlat)\n",
    "lonv, latv = np.meshgrid(lon, lat, indexing='ij')\n",
    "probs = 100*(latv - latv.min())/(latv.max() - latv.min())\n",
    "\n",
    "heatmap = Heatmap(\n",
    "    locations=[[latv[i,j], lonv[i,j], probs[i,j]] for i in range(nlon) for j in range(nlat)],\n",
    "    radius=20,\n",
    "    gradient={0.0: 'yellow', 0.5: 'green', 1.0: 'blue'}\n",
    ")\n",
    "\n",
    "m.add_layer(heatmap);\n",
    "display(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "m = Map(center=(0, 0), zoom=0)\n",
    "\n",
    "probs_s = 100 - probs\n",
    "\n",
    "heatmap = Heatmap(\n",
    "    locations=[[latv[i,j], lonv[i,j], probs_s[i,j]] for i in range(nlon) for j in range(nlat)],\n",
    "    radius=20,\n",
    "    gradient={0.0: 'blue', 0.5: 'green', 1.0: 'yellow'}\n",
    ")\n",
    "\n",
    "m.add_layer(heatmap);\n",
    "display(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "It is necessary to show the probability of both classes in separate layers, given that the probabilities near 0 have the alpha channel to 1 and are not visible. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from ipyleaflet import Map, Heatmap\n",
    "from random import uniform\n",
    "m = Map(center=(0, 0), zoom=0)\n",
    "\n",
    "\n",
    "nlon, nlat = (180, 90)\n",
    "lon = np.linspace(-180, 180, nlon)\n",
    "lat = np.linspace(-90, 90, nlat)\n",
    "lonv, latv = np.meshgrid(lon, lat, indexing='ij')\n",
    "probs = 100*(latv - latv.min())/(latv.max() - latv.min())\n",
    "\n",
    "heatmap = Heatmap(\n",
    "    locations=[[latv[i,j], lonv[i,j], probs[i,j]] for i in range(nlon) for j in range(nlat)],\n",
    "    radius=20,\n",
    "    gradient={0.0: 'yellow', 0.5: 'green', 1.0: 'blue'}\n",
    ")\n",
    "\n",
    "m.add_layer(heatmap);\n",
    "\n",
    "probs = 100 - probs\n",
    "\n",
    "heatmap = Heatmap(\n",
    "    locations=[[latv[i,j], lonv[i,j], probs[i,j]] for i in range(nlon) for j in range(nlat)],\n",
    "    radius=20,\n",
    "    gradient={0.0: 'blue', 0.5: 'green', 1.0: 'yellow'}\n",
    ")\n",
    "\n",
    "m.add_layer(heatmap);\n",
    "display(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Avoid projection deformation\n",
    "\n",
    "In order to avoid the deformation of the grid from the sphere to the rectangle we can zoom into a smaller region of the map, as the deformation is less apparent. But the zoom and the heatmap still behave in a non-ideal way. It is very difficult to adjust a proper set of parameters for the heatmap to work with short and long zoom levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from ipyleaflet import Map, Heatmap\n",
    "from random import uniform\n",
    "m = Map(center=(55, 0), zoom=4.3)\n",
    "\n",
    "\n",
    "nlon, nlat = (100, 100)\n",
    "lon = np.linspace(-10, 10, nlon)\n",
    "lat = np.linspace(50, 60, nlat)\n",
    "lonv, latv = np.meshgrid(lon, lat, indexing='ij')\n",
    "probs = 100*(latv - latv.min())/(latv.max() - latv.min())\n",
    "\n",
    "color_per_class = [{0.0: 'yellow', 0.5: 'green', 1.0: 'blue'},\n",
    "                   {0.0: 'blue', 0.5: 'green', 1.0: 'yellow'}]\n",
    "\n",
    "for (gradient, values) in zip(*[color_per_class, [probs, 100 - probs]]):\n",
    "    heatmap = Heatmap(\n",
    "        locations=[[latv[i,j], lonv[i,j], values[i,j]] for i in range(nlon) for j in range(nlat)],\n",
    "        radius=20,\n",
    "        gradient=gradient\n",
    "    )\n",
    "\n",
    "    m.add_layer(heatmap);\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Example of linear classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "display(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "pip install requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Country contours and Search Engine\n",
    "\n",
    "The following is an example of country contours and the option to search for country names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import requests\n",
    "\n",
    "from ipyleaflet import AwesomeIcon, GeoJSON, Map, Marker, LayerGroup, SearchControl\n",
    "\n",
    "m = Map(zoom=3, center=[19.1646, 72.8493])\n",
    "\n",
    "if not os.path.exists('countries.geo.json'):\n",
    "      url = 'https://raw.githubusercontent.com/jupyter-widgets/ipyleaflet/master/examples/countries.geo.json'\n",
    "      r = requests.get(url)\n",
    "      with open('countries.geo.json', 'w') as f:\n",
    "        f.write(r.content.decode(\"utf-8\"))\n",
    "\n",
    "with open(\"countries.geo.json\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "countries = GeoJSON(data=data)\n",
    "\n",
    "layer_group = LayerGroup(layers=(countries,))\n",
    "marker = Marker(icon=AwesomeIcon(name=\"check\", marker_color='green', icon_color='darkred'))\n",
    "\n",
    "m.add_control(SearchControl(\n",
    "  position=\"topleft\",\n",
    "  layer=layer_group,\n",
    "  zoom=4,\n",
    "  property_name='name',\n",
    "  marker=marker\n",
    "))\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipyleaflet import Map, ImageOverlay\n",
    "\n",
    "m = Map(center=(25, -115), zoom=4)\n",
    "\n",
    "image = ImageOverlay(\n",
    "    #url=\"https://i.imgur.com/06Q1fSz.png\",\n",
    "    url=\"./06Q1fSz_alpha.png\",\n",
    "    #url='../06Q1fSz.png',\n",
    "    bounds=((13, -130), (32, -100))\n",
    ")\n",
    "\n",
    "m.add_layer(image);\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import ipyleaflet\n",
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "import requests\n",
    "from ipywidgets import link, FloatSlider\n",
    "from branca.colormap import linear\n",
    "\n",
    "def load_data(url, filename, file_type):\n",
    "    r = requests.get(url)\n",
    "    with open(filename, 'w') as f:\n",
    "        f.write(r.content.decode(\"utf-8\"))\n",
    "    with open(filename, 'r') as f:\n",
    "        return file_type(f)\n",
    "\n",
    "geo_json_data = load_data(\n",
    "    'https://raw.githubusercontent.com/jupyter-widgets/ipyleaflet/master/examples/us-states.json',\n",
    "    'us-states.json',\n",
    "     json.load)\n",
    "\n",
    "unemployment = load_data(\n",
    "    'https://raw.githubusercontent.com/jupyter-widgets/ipyleaflet/master/examples/US_Unemployment_Oct2012.csv',\n",
    "    'US_Unemployment_Oct2012.csv',\n",
    "     pd.read_csv)\n",
    "\n",
    "unemployment =  dict(zip(unemployment['State'].tolist(), unemployment['Unemployment'].tolist()))\n",
    "\n",
    "layer = ipyleaflet.Choropleth(\n",
    "    geo_data=geo_json_data,\n",
    "    choro_data=unemployment,\n",
    "    colormap=linear.YlOrRd_04,\n",
    "    border_color='black',\n",
    "    style={'fillOpacity': 0.8, 'dashArray': '5, 5'})\n",
    "\n",
    "m = ipyleaflet.Map(center = (43,-100), zoom = 4)\n",
    "m.add_layer(layer)\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The two coordinates in the map are\n",
    "\n",
    "- longitude : [-180, 180] (West of the map, East of the map)\n",
    "- latitude : [-90, 90] (South pole, North pole)\n",
    "\n",
    "Altough while writing or speaking it is more common to use only positive values, and indicate West as a negative longitude and South as a negative latitude.\n",
    "The longitude zero corresponds to the prime meridian which crosses Greenwich, while the latitude zero corresponds to the equator line. The Null island is in the intersection of these two lines (0N, 0E) in hte Gulf of Guinea which depicts a weather buoy maintained by PIRATA (Prediction and Research Moored Array in the Atlantic).\n",
    "\n",
    "The coordinates are always specified as latitude first and longitude second, eg. Bristol center is 51.4545° N, 2.5879° W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipyleaflet\n",
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "import requests\n",
    "from ipywidgets import link, FloatSlider\n",
    "from branca.colormap import linear\n",
    "\n",
    "regions = {\n",
    "    \"type\": \"FeatureCollection\",\n",
    "    \"features\":[{\n",
    "        \"type\":\"Feature\",\n",
    "        \"id\":\"YS\",\n",
    "        \"properties\":{\"name\":\"Yellow Square\"},\n",
    "        \"geometry\":{\n",
    "            \"type\":\"Polygon\",\n",
    "            \"coordinates\": [[[-2,2],\n",
    "                             [-2,-2],\n",
    "                             [2,-2],\n",
    "                             [2,2]]]\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\":\"Feature\",\n",
    "        \"id\":\"RS\",\n",
    "        \"properties\":{\"name\":\"Red Square\"},\n",
    "        \"geometry\":{\n",
    "            \"type\":\"Polygon\",\n",
    "            \"coordinates\": [[[2,2],\n",
    "                             [8,2],\n",
    "                             [8,8],\n",
    "                             [2,8]]]\n",
    "        }\n",
    "    }]\n",
    "}\n",
    "\n",
    "colors = {'YS': 0, 'RS': 1}\n",
    "\n",
    "layer = ipyleaflet.Choropleth(\n",
    "    geo_data=regions,\n",
    "    choro_data=colors,\n",
    "    colormap=linear.YlOrRd_04,\n",
    "    border_color='black',\n",
    "    style={'fillOpacity': 0.7, 'dashArray': '5, 5'})\n",
    "\n",
    "m = ipyleaflet.Map(center = (0,0), zoom = 4)\n",
    "m.add_layer(layer)\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification problem\n",
    "\n",
    "First we will generate a synthethic dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spain_center = (40.4637, -3.7492) # latitude longitude (+N, +E) or (-S, -W)\n",
    "france_center = (46.2276, 2.2137) # latitude, longitude\n",
    "andorra_center = (42.5063, 1.5218) # \n",
    "\n",
    "def latlong_to_xy(coordinates):\n",
    "    ''' Convert coordinates from X,Y space into latitude and longitude'''\n",
    "    if len(coordinates) > 0 and (type(coordinates[0]) not in [float, int]):\n",
    "        return [list(reversed(ll)) for ll in coordinates]\n",
    "    return list(reversed(coordinates))\n",
    "\n",
    "def xy_to_latlong(coordinates):\n",
    "    ''' Convert coordinates from latitude longitude space into X,Y space'''\n",
    "    return latlong_to_xy(coordinates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example with two Gaussians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two Gaussians\n",
    "samples_c0 = 500\n",
    "samples_c1 = 500\n",
    "x_class_0 = np.random.multivariate_normal(mean=spain_center, cov=[[12,0],[0,12]], size=samples_c0)\n",
    "x_class_1 = np.random.multivariate_normal(mean=france_center, cov=[[12,0],[0,12]], size=samples_c1)\n",
    "y_class_0 = np.zeros((samples_c0, 1), dtype=int)\n",
    "y_class_1 = np.ones((samples_c1, 1), dtype=int)\n",
    "\n",
    "x = np.vstack((x_class_0, x_class_1))\n",
    "y = np.vstack((y_class_0, y_class_1)).squeeze()\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "x, y = shuffle(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example with 2 clusters per class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "\n",
    "# FIXME Clarify the coordinates (x1, x2) and (lat, long)\n",
    "x, y = make_classification(n_samples=1000, n_features=2,\n",
    "                           n_informative=2, n_redundant=0,\n",
    "                           n_classes=2, n_clusters_per_class=2,\n",
    "                           flip_y=0.2, scale=(6, 1),\n",
    "                           shift=andorra_center,\n",
    "                           random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple blobs per class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "x, y = make_blobs(n_samples=500, n_features=2, centers=20,\n",
    "                  cluster_std=2.0, center_box=(-20.0, 20.0),\n",
    "                  shuffle=True, random_state=42)\n",
    "\n",
    "x += andorra_center\n",
    "\n",
    "y[y<10] = 0\n",
    "y[y>=10] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1)\n",
    "scatter = ax.scatter(x[:,1], x[:,0], c=y, alpha=0.7)\n",
    "ax.legend(handles=scatter.legend_elements(num=[0,1])[0], labels=['spain', 'france'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations_c0 = np.hstack((x[y==0], np.ones((sum(y==0), 1))))\n",
    "locations_c1 = np.hstack((x[y==1], np.ones((sum(y==1), 1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipyleaflet import Map, basemaps, basemap_to_tiles, Circle\n",
    "m = Map(center=andorra_center, zoom=4)\n",
    "\n",
    "class_color = ['blue', 'yellow']\n",
    "# FIXME One layer per circle gets laggy, we show only 100 points\n",
    "for sample_x, sample_y in zip(x[:100].tolist(), y[:100]):\n",
    "    circle = Circle()\n",
    "    circle.location = sample_x\n",
    "    circle.radius = 100\n",
    "    circle.color = class_color[sample_y]\n",
    "    circle.fill_color = class_color[sample_y]\n",
    "\n",
    "    m.add_layer(circle)\n",
    "display(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "m = Map(center=(40.4637, -3.7492), zoom=4)\n",
    "\n",
    "for color, location in [('blue', locations_c0.tolist()),\n",
    "                        ('yellow', locations_c1.tolist())]:\n",
    "    heatmap = Heatmap(\n",
    "        locations=location,\n",
    "        radius=5,\n",
    "        gradient={0.0: color, 1.0: color},\n",
    "        min_opacity=1,\n",
    "    )\n",
    "\n",
    "    m.add_layer(heatmap);\n",
    "\n",
    "display(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We train a Logistic Regression to discriminate the two classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "#clf = LogisticRegression()\n",
    "#clf = RandomForestClassifier()\n",
    "clf = SVC(C=10000, probability=True)\n",
    "clf.fit(x, y)\n",
    "\n",
    "print('Training accuracy = {:.3f}'.format(np.mean(clf.predict(x) == y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "And next we see the probabilities given in a large region around both classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "nlon, nlat = (200, 200)\n",
    "lon = np.linspace(-180, 180, nlon)\n",
    "lat = np.linspace(-90, 90, nlat)\n",
    "lonv, latv = np.meshgrid(lon, lat, indexing='ij')\n",
    "center = andorra_center\n",
    "\n",
    "# FIXME Use the predicted probabilities\n",
    "probs = clf.predict_proba(np.hstack((latv.reshape(-1,1), lonv.reshape(-1,1))))\n",
    "#probs = np.log((center -np.hstack((lonv.reshape(-1, 1), latv.reshape(-1,1))))**2)/100\n",
    "#probs = np.hstack((probs, -1*probs))\n",
    "\n",
    "\n",
    "m = Map(center=center, zoom=4)\n",
    "\n",
    "for c, gradient in enumerate([{0.0: 'blue', 1.0: 'blue'},\n",
    "                              {0.0: 'yellow', 1.0: 'yellow'}]):\n",
    "    location_prob_c = probs[:,c].reshape(lonv.shape)*100 # FIXME If I select a value between 0 and 1, the color is barely visible\n",
    "\n",
    "    heatmap = Heatmap(\n",
    "        locations=[[latv[i,j], lonv[i,j], location_prob_c[i,j]] for i in range(nlon) for j in range(nlat)],\n",
    "        radius=40,\n",
    "        gradient=gradient,\n",
    "        min_opacity=0.0,\n",
    "    )\n",
    "\n",
    "    m.add_layer(heatmap);\n",
    "\n",
    "\n",
    "display(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Another option for interactive plots\n",
    "#import mpld3\n",
    "#mpld3.enable_notebook()\n",
    "# We need to invert x1 and x2 given that latitude and longitude are in the oposite order than xy space\n",
    "plt.scatter(x[:,1], x[:,0], c=y)\n",
    "cs = plt.contour(lonv, latv, probs[:,1].reshape(lonv.shape),\n",
    "                 [0, 0.000001, 0.0001, 0.1, 0.3, 0.5,\n",
    "                  0.7, 0.9, 0.9999, 0.999999, 1])\n",
    "plt.xlim([-30, 30])\n",
    "plt.ylim([20, 60])\n",
    "plt.show()\n",
    "#cs.collections[0].get_paths()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain the contour lines for the latitude and longitude variant\n",
    "fig, ax = plt.subplots(1, figsize=(12, 9))\n",
    "cs = ax.contour(latv, lonv, probs[:,1].reshape(lonv.shape),\n",
    "                 [0, 0.000001, 0.0001, 0.1, 0.3, 0.5,\n",
    "                  0.7, 0.9, 0.9999, 0.999999, 1]);\n",
    "ax.scatter(x[:,0], x[:,1], c=y, edgecolor='black')\n",
    "ax.set_ylim([-30, 30])\n",
    "ax.set_xlim([20, 60])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipyleaflet import Map, Polyline\n",
    "\n",
    "m = Map(center=andorra_center, zoom=5)\n",
    "\n",
    "# FIXME The current code only uses one of the lines for each level (see p.get_paths()[0])\n",
    "lines = [p.get_paths()[0].vertices.tolist() for p in cs.collections if p.get_paths()]\n",
    "colors = [linear.viridis(i/len(lines)) for i in range(len(lines))]\n",
    "\n",
    "for (line, color) in zip(lines, colors):\n",
    "    l_layer = Polyline(\n",
    "        locations=line,\n",
    "            color=color,\n",
    "            fill=False\n",
    "        )\n",
    "    m.add_layer(l_layer)\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "regions = {\n",
    "    \"type\": \"FeatureCollection\",\n",
    "    \"features\":[]\n",
    "}\n",
    "\n",
    "colors = {str(i): i/(len(lines)-1) for i in range(len(lines)-1)}\n",
    "\n",
    "# TODO Why do I need to invert latitude and longitude in the polygons?\n",
    "lines_rev = [[list(reversed(point)) for point in line] for line in lines]\n",
    "\n",
    "for i in range(len(lines_rev) - 1):\n",
    "    # FIXME This method uses the first line of two consecutive levels to create a closed shape.\n",
    "    #       This works for a linear classifier, but needs to be generalised to models with multiple lines\n",
    "    #       at the same level.\n",
    "    l1 = lines_rev[i]\n",
    "    l2 = lines_rev[i+1]\n",
    "    polygon = np.concatenate((l1, list(reversed(l2)))).tolist()\n",
    "    regions[\"features\"].append({\n",
    "            \"type\":\"Feature\",\n",
    "            \"id\":str(i),\n",
    "            \"properties\":{\"name\":\"Yellow Square\"},\n",
    "            \"geometry\":{\n",
    "                \"type\":\"Polygon\",\n",
    "                \"coordinates\": [polygon]\n",
    "            }\n",
    "        })\n",
    "\n",
    "layer = ipyleaflet.Choropleth(\n",
    "    geo_data=regions,\n",
    "    choro_data=colors,\n",
    "    colormap=linear.viridis,\n",
    "    border_color='black',\n",
    "    style={'fillOpacity': 0.5, 'dashArray': '5, 5'})\n",
    "\n",
    "m = Map(center=andorra_center, zoom=5)\n",
    "m.add_layer(layer)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Another option for interactive plots\n",
    "import mpld3\n",
    "mpld3.enable_notebook()\n",
    "fig, ax = plt.subplots(1, figsize=(12, 9))\n",
    "cs = ax.contourf(lonv, latv, probs[:,1].reshape(lonv.shape),\n",
    "                 [0, 0.000001, 0.0001, 0.1, 0.3, 0.5,\n",
    "                  0.7, 0.9, 0.9999, 0.999999, 1], alpha=0.8)\n",
    "ax.scatter(x[:,1], x[:,0], c=y, edgecolor='black')\n",
    "ax.set_xlim([-30, 30])\n",
    "ax.set_ylim([20, 60])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "regions = {\n",
    "    \"type\": \"FeatureCollection\",\n",
    "    \"features\":[]\n",
    "}\n",
    "\n",
    "\n",
    "contour_list = []\n",
    "for collection in cs.collections:\n",
    "    contour_list.append([])\n",
    "    paths_list = collection.get_paths()\n",
    "    for path in paths_list:\n",
    "        contour_list[-1].append(path.vertices.tolist())\n",
    "\n",
    "colors = {str(i): i/(len(contour_list)) for i in range(len(contour_list))}\n",
    "\n",
    "# TODO It seems that polygons use the longitude first and latitude second\n",
    "\n",
    "for i, polygon_list in enumerate(contour_list):\n",
    "    for polygon in polygon_list:\n",
    "        regions[\"features\"].append({\n",
    "                \"type\":\"Feature\",\n",
    "                \"id\":str(i),\n",
    "                \"properties\":{\"name\":\"contours\"},\n",
    "                \"geometry\":{\n",
    "                    \"type\":\"Polygon\",\n",
    "                    \"coordinates\": [polygon]\n",
    "                }\n",
    "            })\n",
    "\n",
    "layer = ipyleaflet.Choropleth(\n",
    "    geo_data=regions,\n",
    "    choro_data=colors,\n",
    "    colormap=linear.viridis,\n",
    "    border_color='black',\n",
    "    style={'fillOpacity': 0.5, 'dashArray': '5, 5'})\n",
    "\n",
    "m = Map(center=andorra_center, zoom=5)\n",
    "m.add_layer(layer)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "rise": {
   "minScale": 1.25,
   "width": "80%"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
